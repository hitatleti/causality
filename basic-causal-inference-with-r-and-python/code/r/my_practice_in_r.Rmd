---
title: "my_practice_in_R"
author: "Hisanori Tanaka"
date: "2023-04-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter01

#### 1.9　simple exercise in R

```{r 1.9.1, include=TRUE}
rm(list = ls()) # ワークスペースをクリアにする
data01 = read.csv("../../data/data01.csv")
data01
# head(data01)とすれば, 最初の6行ぶんを表示
```

summary関数を使って基本統計量を表示

```{r 1.9.2, include=TRUE}
summary(data01)
```

## Chapter02　潜在的結果変数の枠組み


#### 2.1　潜在的結果変数の枠組み：具体例

単純な「前後比較」や「集団ごとの平均の差の比較」によって因果を推し測ろうとすることはよくある誤り. <br>
統計的因果推論では, 潜在的結果の差から計算される因果効果を推定する. （ただし, 実際に潜在的結果は観測されないことに注意. ）

#### 2.2　潜在的結果変数の枠組み：理論

```{r 2.2.1, include=TRUE}
rm(list = ls())
data02 = read.csv("../../data/data02.csv")
attach(data02)
head(data02)
```

```{r 2.2.2, include=TRUE}
summary(data02)
```

#### 2.3　処置効果１：個体因果効果

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 2.3：個体因果効果（ICE: individual causal effect） </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
$$ \tau_{i} = \gamma_{i}(1) - \gamma_{i}(0) $$ </div> <br>


```{r 2.3.1, include=TRUE}
y1t - y0t
```

```{r 2.3.2, include=TRUE}
y3 - x1
```

```{r 2.3.3, include=TRUE}
y1 - y0
```

潜在的結果は一方が観測された時, 他方は観測されないため, ITEは定義できても観測も推定もできない. 

#### 2.4　処置効果２：平均処置効果

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 2.4：個体因果効果（ICE: individual causal effect）あるいは 平均処置効果（ATE） </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
$$ \tau_{\mathrm{ATE}} = \mathrm{E} [ \gamma_{i}(1) - \gamma_{i}(0) ] = \mathrm{E} [ \gamma_{i}(1)] - \mathrm{E} [ \gamma_{i}(0)] $$ </div> <br>

```{r 2.4.1, include=TRUE}
mean(y1t) - mean(y0t)
```
```{r 2.4.2, include=TRUE}
mean(y3) - mean(x1)
```
```{r 2.4.3, include=TRUE}
m1 = mean(y1, na.rm = TRUE)
m0 = mean(y0, na.rm = TRUE)
m1 - m0
```

#### 2.5　処置効果３：処置群の平均処置効果

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 2.5：処置群の平均処置効果（ATT: average treatment effect on the treated） </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
$$ \tau_{\mathrm{ATT}} = \mathrm{E} [ \gamma_{i}(1) - \gamma_{i}(0) | T_{i} = 1] = \mathrm{E} [ \gamma_{i}(1) | T_{i} = 1] - \mathrm{E} [ \gamma_{i}(0) | T_{i} = 1] $$ </div> <br>


```{r 2.5.1, include=TRUE}
# 真のATT
mt1 = mean(y1t[t1 = 1])
mt0 = mean(y0t[t1 = 1])
mt1 - mt0
```

処置が無作為である　$\Rightarrow$　ATE $=$ ATT <br>
処置が無作為でない　$\Rightarrow$　ATE $\neq$ ATT　となる可能性がある <br>

#### 2.6　交絡因子

単純な推定量にはほとんどの場合何らかの変数による交絡（confounding）がある. 統計的因果推論では, 処置の割付けがどのように行われているのかは非常に重要である. 

##### 2.6.2　方向付き非巡回グラフ（DAG）

因果関係や交絡の有無を視覚化する方法として, 方向付き非巡回グラフ（DAG: Directed Acyclic Graph）というものがある. 

#### 2.7　無作為抽出と無作為割付け

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 2.7：無作為割付け </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
無作為割付けとは, 標本データを処置群と統制群に無作為に分けることである </div> <br>

無作為抽出の割付Ver.と考えればよい. <br>

また, 処置群と統制群に無作為割付けする研究方法を実験研究, そうでない研究方法を観察研究と呼ぶ. 

#### 2.8　無作為割付けによる分析の例

```{r 2.8.1, include=TRUE}
set.seed(1)
r0 = runif(20, 0, 1)
r1 = round(r0, 0)
y2 = NULL
y2[r1 == 1] = y1t[r1 == 1]
y2[r1 == 0] = y0t[r1 == 0]
```

```{r 2.8.2, include=TRUE}
r1
```

```{r 2.8.3, include=TRUE}
y2
```

```{r 2.8.4, include=TRUE}
mr1 = mean(y2[r1 == 1])
mr0 = mean(y2[r1 == 0])
mr1 - mr0
```

#### 2.10　２標本$t$検定

```{r 2.10.1, include=TRUE}
t.test(y2[r1==1], y2[r1==0], var.equal = FALSE)
```

### Chapter03　統計的因果推論における重要な仮定

#### 3.1　STUVA

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 3.1：STUVA（stable unit treatment value assumption） </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
SUTVAとは, 以下の2つの条件を満たすことである. <br>

<ol>
<li>相互干渉がない
<li>個体に対する隠れた処置がない
</div> <br>

#### 3.8　共変量の役割

<div style="display: inline-block; background: gray; padding: 3px 10px; color: #ffffff;">
<strong> Def 3.8：無交絡性（unconfoundedness） </strong> </div>
<div style="padding: 10px; border: 2px solid gray;"> 
処置の割付けを表す変数$T_{i}$が, 潜在的結果変数の組$\{ \gamma_{i}(1), \gamma_{i}(0) \}$に依存しないことを条件付き独立または無交絡性という. 
$$ \{ \gamma_{i}(1), \gamma_{i}(0) \} \perp T_{i} | \bf{X} $$ </div> <br>

```{r 3.8.1, include=TRUE}
rm(list = ls())
data03 = read.csv("../../data/data03.csv")
attach(data03)
head(data03)
```

```{r 3.8.2, include=TRUE}
summary(data03)
```

```{r 3.8.3, include=TRUE}
mean(y3[t1==1]) - mean(y3[t1==0])
mean(y1t) - mean(y0t)
```

「無視可能な割付け」とは, ナイーブな推定量によって文字通りに「割付けを無視して解析してよい」ということを意味するわけではない. 

### Chapter05　回帰分析の基礎

##### 5.2　数値例で理解する最小二乗法

```{r 5.2.1, include=TRUE}
rm(list = ls())
y1 = c(40, 20, 50, 10)
x1 = c(5, 1, 3, 2)
```

```{r 5.2.2, include=TRUE}
yhat1 = 11.143 + 6.857 * x1
e1 = y1 - yhat1
print(yhat1)
print(e1)
```
```{r 5.2.3, include=TRUE}
yhat2 = 10.909 * x1
e2 = y1 - yhat2
print(yhat2)
print(e2)
```
```{r 5.2.4, include=TRUE}
# 残差の合計は常にゼロである（以下の例では, 丸め誤差のためにゼロにはなっていない）
sum(e1)
sum(e2)
```

```{r 5.2.5, include=TRUE}
sum(e1^2)
sum(e2^2)
```

```{r 5.2.6, include=TRUE}
model1 = lm(y1 ~ x1)
summary(model1)
```

##### 5.4　条件付き期待値としての回帰モデル

```{r 5.4.1, include=TRUE}
rm(list = ls())
y1 = c(seq(9))
x1 = c(rep(1, 3), rep(2, 3), rep(3, 3))
mean(y1)
```
```{r 5.4.2, include=TRUE}
model2 = lm(y1 ~ x1)
summary(model2)
```
```{r 5.4.3, include=TRUE}
plot(x1, y1)
abline(model2)
```

### Chapter06　図で理解する重回帰モデルの基礎

```{r 6.1.1, include=TRUE}
rm(list = ls())
data06 = read.csv("../../data/data06.csv")
attach(data06)
head(data06)
```

```{r 6.1.2, include=TRUE}
summary(data06)
```

```{r 6.3.1, include=TRUE}
summary(data06)
```

### Chapter07　最小二乗法による重回帰モデルの仮定と診断１

```{r 7.2.1, include=TRUE}
rm(list = ls())
data07a = read.csv("../../data/data07a.csv")
head(data07a)
```




























